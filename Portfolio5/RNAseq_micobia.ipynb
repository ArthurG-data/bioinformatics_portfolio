{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio 5\n",
    "## IFN646 semester 2 2023\n",
    "### Arthur Guillaume N11371200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biom import load_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calour as ca\n",
    "from biom import load_table\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = \"metadata.txt\"\n",
    "biom_file = \"otu_table.biom\"\n",
    "phylo_file = \"97_otu_taxonomy.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import the data into calour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A )\n",
    "From Portfolio 4, we were able to detect genes that are differentially expressed (DE) in smokers compared to non-smokers, both in the throat and in the nose. My approach will begin by identifying the bacteria that are differentially expressed exclusively in the throat and in the nose. Once I have the IDs of these bacteria, I will specifically select those features from the metadata table. I will pivot the table to have the sample ID as a column, and each feature will become its own column. For task 4, I will combine the OTU from the nose and from the throat.\n",
    "\n",
    "The next step will be to incorporate airway and smoker features to filter the data and train a model. Before training the model, I will use lasso regression to reduce the number of features under consideration. As illustrated on page 23 of the Week 8 lecture, I will implement the Partial Least Squares Discriminant Analysis (PLS-DA) algorithm for binary classification (supervised machine learning). We will assess the model on a per-sample basis, and then on a per-patient basis. Since patients have multiple samples, I will group the predictions for a subject and declare a person a smoker if 75% or more of the samples have been predicted as positive. This percentage seems to provide more accurate results compared to using 50% or 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) \n",
    "When splitting the data into training and testing sets, we need to ensure that the proportion of smokers is the same in both sets by using the stratify feature. As for sample selection, we will only choose samples from the nose or the throat, depending on the task. To make predictions on a subject basis, we will then test the model on the whole dataset, on declare a subject smoker if more than 75% of samples are predicted smoker==yes. For task 3, we will select all the samples for the training. We will use 30% of the dataset as the testing set. After conducting multiple tests, we found that this value provided the best accuracy. Given the relatively small number of samples, we believe it is preferable to have a larger testing set to obtain the most accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the df\n",
    "meta_df = pd.read_csv(meta_file,index_col=0, sep=\"\\t\")\n",
    "table = load_table(biom_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>airwaysite</th>\n",
       "      <th>antibioticusepast3months</th>\n",
       "      <th>chronic_condition</th>\n",
       "      <th>host_subject_id</th>\n",
       "      <th>respiratorydiseasestatus</th>\n",
       "      <th>sex</th>\n",
       "      <th>sideofbody</th>\n",
       "      <th>smoker</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524.ESC.1.22.NPR</th>\n",
       "      <td>24</td>\n",
       "      <td>Nose</td>\n",
       "      <td>AntibioticUsed.1month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ESC.1.22</td>\n",
       "      <td>NasalCongestion.mild.current</td>\n",
       "      <td>male</td>\n",
       "      <td>Right</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524.ESC.1.22.OPL</th>\n",
       "      <td>24</td>\n",
       "      <td>Throat</td>\n",
       "      <td>AntibioticUsed.1month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ESC.1.22</td>\n",
       "      <td>NasalCongestion.mild.current</td>\n",
       "      <td>male</td>\n",
       "      <td>Left</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Throat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524.ESC.1.22.OPR</th>\n",
       "      <td>24</td>\n",
       "      <td>Throat</td>\n",
       "      <td>AntibioticUsed.1month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ESC.1.22</td>\n",
       "      <td>NasalCongestion.mild.current</td>\n",
       "      <td>male</td>\n",
       "      <td>Right</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Throat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524.ESC.1.23.NPL</th>\n",
       "      <td>24</td>\n",
       "      <td>Nose</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ESC.1.23</td>\n",
       "      <td>NasalCongestion.moderate.current</td>\n",
       "      <td>male</td>\n",
       "      <td>Left</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  age airwaysite antibioticusepast3months chronic_condition  \\\n",
       "#SampleID                                                                     \n",
       "524.ESC.1.22.NPR   24       Nose    AntibioticUsed.1month               Yes   \n",
       "524.ESC.1.22.OPL   24     Throat    AntibioticUsed.1month               Yes   \n",
       "524.ESC.1.22.OPR   24     Throat    AntibioticUsed.1month               Yes   \n",
       "524.ESC.1.23.NPL   24       Nose                     None               Yes   \n",
       "\n",
       "                 host_subject_id          respiratorydiseasestatus   sex  \\\n",
       "#SampleID                                                                  \n",
       "524.ESC.1.22.NPR        ESC.1.22      NasalCongestion.mild.current  male   \n",
       "524.ESC.1.22.OPL        ESC.1.22      NasalCongestion.mild.current  male   \n",
       "524.ESC.1.22.OPR        ESC.1.22      NasalCongestion.mild.current  male   \n",
       "524.ESC.1.23.NPL        ESC.1.23  NasalCongestion.moderate.current  male   \n",
       "\n",
       "                 sideofbody smoker Description  \n",
       "#SampleID                                       \n",
       "524.ESC.1.22.NPR      Right    Yes        Nose  \n",
       "524.ESC.1.22.OPL       Left    Yes      Throat  \n",
       "524.ESC.1.22.OPR      Right    Yes      Throat  \n",
       "524.ESC.1.23.NPL       Left    Yes        Nose  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 145 from the nose and 146 from the throat\n"
     ]
    }
   ],
   "source": [
    "#first, check that every sample from the same subject have the same smoker status\n",
    "nose_df = meta_df[meta_df.airwaysite=='Nose'][['host_subject_id','smoker']]\n",
    "throat_df = meta_df[meta_df.airwaysite=='Throat'][['host_subject_id','smoker']]\n",
    "print(f\"There are {len(nose_df)} from the nose and {len(throat_df)} from the throat\")\n",
    "#find the patient with only one sample and remove\n",
    "unique_id_throat = list(set(throat_df.host_subject_id.values))\n",
    "unique_id_nose = list(set(nose_df.host_subject_id.values))\n",
    "unique_id_nonsmoker=list(set(meta_df[meta_df.smoker=='No']['host_subject_id'].values))\n",
    "unique_id_smoker=list(set(meta_df[meta_df.smoker=='Yes']['host_subject_id'].values))\n",
    "#compare the id of smokers and non smoker\n",
    "for nonsmoker in unique_id_nonsmoker:\n",
    "    if nonsmoker in unique_id_smoker:\n",
    "        print(f'{nonsmoker} is both smoker and non smoker')\n",
    "for smoker in unique_id_smoker:\n",
    "    if smoker in unique_id_nonsmoker:\n",
    "        print(f'{smoker} is both smoker and non smoker')\n",
    "#now find if everyone has a sample in each airwaysite\n",
    "for sample in unique_id_throat:\n",
    "    if sample not in unique_id_nose:\n",
    "        print(f'{sample} has only a throat sample')\n",
    "for sample in unique_id_nose:\n",
    "    if sample not in unique_id_throat:\n",
    "        print(f'{sample} has only a nose sample')\n",
    "#everything looks good, we can start the analysis\n",
    "#map yes to 1 and no to 0\n",
    "meta_df['smoker'] = meta_df['smoker'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For task 2, using only chronic condition and sex was sufficient and had an 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Throat    146\n",
       "Nose      145\n",
       "Name: airwaysite, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3\n",
    "meta_df.airwaysite.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrobiomeAnalysis:\n",
    "    \n",
    "  \n",
    "    def __init__(self, biom_file, meta_file):\n",
    "        self.data = ca.read_amplicon(biom_file, meta_file, normalize=10000, min_reads=1000)\n",
    "        self.biom_table = load_table(biom_file)\n",
    "        self.meta_table = pd.read_csv(meta_file,index_col=0, sep=\"\\t\")\n",
    "        self.headers = ['ID','Kingdom','Phylum','Class','Order','Family','Genus','Specis']\n",
    "    def cluster_features(self):\n",
    "        self.data= self.data.cluster_features()\n",
    "        \n",
    "    def create_phylo_table(self, phylo_file):\n",
    "        self.phylo_table = pd.read_csv(phylo_file,index_col=0,header=None,names=self.headers, sep=\";|\\t\")\n",
    "        for column in self.headers[1:]:\n",
    "             self.phylo_table[column] = self.phylo_table[column].str.split('__').str[1]\n",
    "        ##order by ID for faster search\n",
    "        self.phylo_table=self.phylo_table.reset_index().sort_values(by='ID').reset_index(drop=True)\n",
    "        self.phylo_table['Phylum'] = self.phylo_table['Phylum'].apply(lambda x : x[1:-1])\n",
    "        self.phylo_table['Class'] = self.phylo_table['Class'].apply(lambda x : x[1:-1])\n",
    "        \n",
    "    def filter_samples(self, field, values):\n",
    "        self.data = self.data.filter_samples(field, values)\n",
    "        \n",
    "    def filter_abundance(self, treshold):\n",
    "        self.data = self.data.filter_sum_abundance(treshold)\n",
    "        \n",
    "    def perform_differential_abundance(self, feature,group1, group2):\n",
    "        self.data = self.data.sort_samples(feature)\n",
    "        self.dd = self.data.diff_abundance(feature, group1, group2,  random_seed=2018)\n",
    "        self.differentially_expressed_features = self.dd.feature_metadata\n",
    "        \n",
    "    \n",
    "    def get_feature_ids(self):\n",
    "        # Access the IDs of differentially expressed features\n",
    "        feature_ids = self.differentially_expressed_features.index\n",
    "        return [int(feature_id) for feature_id in feature_ids]\n",
    "    \n",
    "    def get_taxonomy_answers(self):\n",
    "        answers = []\n",
    "       \n",
    "        \n",
    "        int_feature_ids = self.get_feature_ids()\n",
    "        \n",
    "        for ids in int_feature_ids:\n",
    "            matching_rows = self.phylo_table[self.phylo_table[\"ID\"] == ids]\n",
    "            answer = []\n",
    "            \n",
    "            if not matching_rows.empty:\n",
    "                for column in reversed(matching_rows.columns):\n",
    "                    if(column in [\"Specis\",\"Genus\" ] or len(answer)==0):\n",
    "                        if matching_rows.at[matching_rows.index[0], column]:\n",
    "                            answer.insert(0, matching_rows.at[matching_rows.index[0], column])\n",
    "                    else:\n",
    "                        break\n",
    "            answers.append([ids, \" \".join(answer)])\n",
    "        \n",
    "        return answers\n",
    "\n",
    "    def plot_differential_abundance(self, field):\n",
    "        self.dd.plot(sample_field=field, gui='jupyter')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 00:11:40 WARNING Found 1 samples that have metadata but do not have data. These samples have been dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorie\\AppData\\Local\\Temp\\ipykernel_4908\\2639038977.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  self.phylo_table = pd.read_csv(phylo_file,index_col=0,header=None,names=self.headers, sep=\";|\\t\")\n"
     ]
    }
   ],
   "source": [
    "##obtain DA fomr samples from the nose\n",
    "task3_nose = MicrobiomeAnalysis(biom_file, meta_file)\n",
    "task3_nose.filter_abundance(10)\n",
    "task3_nose.cluster_features()\n",
    "task3_nose.filter_samples('Description','Nose')\n",
    "task3_nose.perform_differential_abundance('smoker', 'Yes', 'No')\n",
    "\n",
    "task3_nose.create_phylo_table(phylo_file)\n",
    "task3_answer_nose = task3_nose.get_taxonomy_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 00:11:48 WARNING Found 1 samples that have metadata but do not have data. These samples have been dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorie\\AppData\\Local\\Temp\\ipykernel_4908\\2639038977.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  self.phylo_table = pd.read_csv(phylo_file,index_col=0,header=None,names=self.headers, sep=\";|\\t\")\n"
     ]
    }
   ],
   "source": [
    "##obtain DA fomr samples from the throat\n",
    "task3_throat = MicrobiomeAnalysis(biom_file, meta_file)\n",
    "task3_throat.filter_abundance(10)\n",
    "task3_throat.cluster_features()\n",
    "task3_throat.filter_samples('Description','Throat')\n",
    "task3_throat.perform_differential_abundance('smoker', 'Yes', 'No')\n",
    "\n",
    "task3_throat.create_phylo_table(phylo_file)\n",
    "task3_answer_throat = task3_throat.get_taxonomy_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 00:11:56 WARNING Found 1 samples that have metadata but do not have data. These samples have been dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorie\\AppData\\Local\\Temp\\ipykernel_4908\\2639038977.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  self.phylo_table = pd.read_csv(phylo_file,index_col=0,header=None,names=self.headers, sep=\";|\\t\")\n"
     ]
    }
   ],
   "source": [
    "##obtain DA fomr samples from tall samples\n",
    "task3_smoker = MicrobiomeAnalysis(biom_file, meta_file)\n",
    "task3_smoker.filter_abundance(10)\n",
    "task3_smoker.cluster_features()\n",
    "task3_smoker.perform_differential_abundance('smoker', 'Yes', 'No')\n",
    "\n",
    "task3_smoker.create_phylo_table(phylo_file)\n",
    "task3_smoker = task3_smoker.get_taxonomy_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throat: 54 DA\n",
      "Nose: 126 DA\n"
     ]
    }
   ],
   "source": [
    "#find differences between nose and throat\n",
    "nose_bact_diff = []\n",
    "throat_bact_diff =[]\n",
    "\n",
    "\n",
    "for bact in task3_answer_nose:\n",
    "    if bact not in task3_answer_throat:\n",
    "        nose_bact_diff.append(bact[0]) \n",
    "for bact in task3_answer_throat:\n",
    "    if bact not in task3_answer_nose:\n",
    "        throat_bact_diff.append(bact[0])\n",
    "print(f\"Throat: {len(throat_bact_diff)} DA\")\n",
    "print(f\"Nose: {len(nose_bact_diff)} DA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def doPCASVMClassification(meta_table, bact_diff, number_components, filter=False, localisation='default'):\n",
    "    number_components = number_components\n",
    "#now create a table with the samples as index, the identified genes as column, and add the smoker target\n",
    "    # Load the Biom table\n",
    "    biom_table = load_table(biom_file)\n",
    "\n",
    "\n",
    "    # Convert Biom table to a DataFrame\n",
    "    data = biom_table.to_dataframe()\n",
    "\n",
    "    # Ensure the index is in integer format and sorted\n",
    "    data.index = data.index.astype(int)\n",
    "    data.sort_index(ascending=True, inplace=True)\n",
    " \n",
    "    # Filter data based on 'nose_bact_diff'\n",
    "    data= data[data.index.isin(bact_diff)]\n",
    "    # Transpose and reset the index to have samples as rows\n",
    "    pivot = data.transpose().reset_index()\n",
    "    pivot.rename(columns={'index': 'samples'}, inplace=True)\n",
    "    # Add 'smoker',and airwaysite information from the metadata table\n",
    "    pivot['smoker'] = pivot['samples'].map(meta_table['smoker'])\n",
    "    pivot['airwaysite'] = pivot['samples'].map(meta_table['airwaysite'])\n",
    "    pivot['host_subject_id'] = pivot['samples'].map(meta_table['host_subject_id'])\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    pivot_filtered = pivot.copy()\n",
    "    #filter for nose only\n",
    "    if(filter and localisation!='default'):\n",
    "        pivot_filtered = pivot_filtered[pivot_filtered['airwaysite']==localisation]\n",
    "    X= pivot_filtered.drop(['smoker', 'samples', 'airwaysite','host_subject_id'], axis=1)\n",
    "    X.columns = X.columns.astype(str)\n",
    "    features_cols = list(X.columns)\n",
    "    X= np.array(X)\n",
    "    #scale the data\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y= pivot_filtered.smoker.values\n",
    "    #feature resuction with lasso, first step is to find the best value for alpha; we are not interested in the absolute best result, so we won't look for convergence\n",
    "    lasso_cv = LassoCV(alphas=np.logspace(-6, 6, 100), cv=5)  \n",
    "    lasso_cv.fit(X_scaled, y)\n",
    "    #get the best alha from cross validation\n",
    "    best_alpha = lasso_cv.alpha_\n",
    "    #create the model\n",
    "    lasso_best = Lasso(alpha=best_alpha)\n",
    "    lasso_best.fit(X_scaled, y)\n",
    "    #selected the features with a non 0 lasso coef from X\n",
    "    X_selected = X_scaled[:, np.abs(lasso_best.coef_) > 0]\n",
    "    print(f\"number of feature used:{len(X_selected[0])}\")\n",
    "    \n",
    "    #split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.array(X_selected), y, test_size=0.3, random_state=42, stratify=y)\n",
    "    #Now build a model\n",
    "    pls_binary = PLSRegression(n_components=number_components)\n",
    "    # Fit the training set\n",
    "    pls_binary.fit(X_train, y_train)\n",
    "    # \"Force\" binary prediction by thresholding\n",
    "    binary_prediction = (pls_binary.predict(X_test)[:,0] > 0.5).astype('uint8')\n",
    "    binary_prediction_train = (pls_binary.predict(X_train)[:,0] > 0.5).astype('uint8')\n",
    "    #test the model on the unfilted dataset\n",
    "    subject_id = pivot[['smoker', 'host_subject_id']]\n",
    "    X_all= pivot.drop(['smoker', 'samples', 'airwaysite','host_subject_id'], axis=1)\n",
    "    X_all.columns = X_all.columns.astype(str)\n",
    "    X_all= np.array(X_all)\n",
    "    #scale the data\n",
    "    X_all = scaler.transform(X_all)\n",
    "    \n",
    "    X_all_selected = X_all[:, np.abs(lasso_best.coef_) > 0]\n",
    "\n",
    "\n",
    "    \n",
    "    y_all= pivot.smoker.values\n",
    "    binary_prediction_all = (pls_binary.predict(X_all_selected)[:,0] > 0.5).astype('uint8')\n",
    "   \n",
    "    #now for each subject ID, check if at least 1 is 0. To do that, groupby id, compute mean set to 1 of >0.75\n",
    "    subject_id=subject_id.assign(predicted=binary_prediction_all)\n",
    "    subject_id = subject_id.groupby('host_subject_id').mean()\n",
    "    subject_id.predicted = subject_id.predicted.apply(lambda x : 0 if x < 0.75 else 1)\n",
    "    y_pred_agg=np.array(subject_id.predicted.values)\n",
    "    y_real =np.array(subject_id.smoker.values)\n",
    "  \n",
    "    \n",
    "    #evaluation\n",
    "    accuracy_all = accuracy_score(y_real,y_pred_agg)\n",
    "    accuracy = accuracy_score(y_test, binary_prediction)\n",
    "    accuracy_train = accuracy_score(y_train, binary_prediction_train)\n",
    "    report = classification_report(y_test, binary_prediction)\n",
    "    report_all = classification_report(y_real,y_pred_agg)\n",
    "    print(f'Accuracy  test {localisation}: {accuracy}')\n",
    "    print(f'Accuracy  train {localisation}: {accuracy_train}')\n",
    "    print(f'Confusion table for test on sample from {localisation}')\n",
    "    print(report)\n",
    "   \n",
    "    print(f'Accuracy all dataset: {accuracy_all}')\n",
    "    print(f'Confusion table for test on all samples, subject classification')\n",
    "    print(report_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feature used:32\n",
      "Accuracy  test Nose: 0.8863636363636364\n",
      "Accuracy  train Nose: 0.8415841584158416\n",
      "Confusion table for test on sample from Nose\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88        22\n",
      "           1       0.84      0.95      0.89        22\n",
      "\n",
      "    accuracy                           0.89        44\n",
      "   macro avg       0.89      0.89      0.89        44\n",
      "weighted avg       0.89      0.89      0.89        44\n",
      "\n",
      "Accuracy all dataset: 0.821917808219178\n",
      "Confusion table for test on all samples, subject classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.72      0.80        36\n",
      "         1.0       0.77      0.92      0.84        37\n",
      "\n",
      "    accuracy                           0.82        73\n",
      "   macro avg       0.83      0.82      0.82        73\n",
      "weighted avg       0.83      0.82      0.82        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doPCASVMClassification(meta_df,nose_bact_diff, 1, filter=True, localisation='Nose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only samples from the nose for the Discriminant Analysis (DA) and subsequently for training and testing the model, we achieved an accuracy of 0.89. We utilized a single component, and out of 126 features, 32 were selected for sparse PLS. Among all the samples from the nose, we correctly identified 95% of the smokers and 83 of the non-smokers, with our predictions for smokers being accurate 84% of the time. The fact that the testing accuracy is higher than the training accuracy suggests there is no overfitting.\n",
    "\n",
    "We then tested our model on the entire dataset, grouping results when multiple samples were available. The accuracy reduced to 82%, and the precision for smokers dropped significantly to 77%. Overall, the model had an average precision of 83% and recall of 82%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feature used:29\n",
      "Accuracy  test Throat: 0.75\n",
      "Accuracy  train Throat: 0.8811881188118812\n",
      "Confusion table for test on sample from Throat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74        22\n",
      "           1       0.74      0.77      0.76        22\n",
      "\n",
      "    accuracy                           0.75        44\n",
      "   macro avg       0.75      0.75      0.75        44\n",
      "weighted avg       0.75      0.75      0.75        44\n",
      "\n",
      "Accuracy all dataset: 0.821917808219178\n",
      "Confusion table for test on all samples, subject classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.83      0.82        36\n",
      "         1.0       0.83      0.81      0.82        37\n",
      "\n",
      "    accuracy                           0.82        73\n",
      "   macro avg       0.82      0.82      0.82        73\n",
      "weighted avg       0.82      0.82      0.82        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doPCASVMClassification(meta_df,throat_bact_diff,1, filter=True, localisation='Throat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only samples from the throat for the Discriminant Analysis (DA) and then for training, we achieved an accuracy of 0.75. We utilized one component, and out of 54 features, 29 were selected. Among all the samples from the throat, we correctly identified 77% of the smokers and 73 of the non-smokers, with our predictions for smokers being correct 74% of the time. The fact that the training accuracy is higher than the testing accuracy indicates some overfitting.\n",
    "\n",
    "When deploying our model on a per-patient basis, the accuracy increased to 82%. Results were comparable to the model trained on samples from the nose but with lower recall for positive results and a higher recall for negative results. Overall precision and recall were similar to the results obtained with the model trained using samples from the nose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feature used:63\n",
      "Accuracy  test default: 0.7471264367816092\n",
      "Accuracy  train default: 0.8226600985221675\n",
      "Confusion table for test on sample from default\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77        43\n",
      "           1       0.82      0.64      0.72        44\n",
      "\n",
      "    accuracy                           0.75        87\n",
      "   macro avg       0.76      0.75      0.74        87\n",
      "weighted avg       0.76      0.75      0.74        87\n",
      "\n",
      "Accuracy all dataset: 0.8082191780821918\n",
      "Confusion table for test on all samples, subject classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.84        36\n",
      "         1.0       1.00      0.62      0.77        37\n",
      "\n",
      "    accuracy                           0.81        73\n",
      "   macro avg       0.86      0.81      0.80        73\n",
      "weighted avg       0.86      0.81      0.80        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#combine all OTUs DA\n",
    "all_out = throat_bact_diff+nose_bact_diff\n",
    "#here the 'NOse' parameter is a something I need to clean in my code, it does nothing here , we take all the samples\n",
    "doPCASVMClassification(meta_df, all_out, 1, filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the samples and combining the OTUs from both the nose and the throat, we achieved an accuracy of 75%. However, we observed some overfitting, as indicated by a training accuracy of 82%. The model was conservative, detecting only 64% of the smokers, although with a precision of 82%. These results were worse than the test results from the model trained on either the nose or the throat alone on the entire dataset, but the precision for positive results was similar (77% for the nose model and 83% for the throat). The recall for positive results was also lower for both models, at 64% compared to 92% and 81% for the nose and throat, respectively. We still observed a fair amount of overfitting.\n",
    "\n",
    "However, when we moved from the sample level to the subject level, the results were decent, with an accuracy of 81%. The model made no errors in positive classification, but 38% of the positives were misclassified. The overall recall of 81% and precision were similar to the model trained on the throat or nose, but the precision was better, at 86% compared to 83% or 82% for the nose or the throat, respectively"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataMining]",
   "language": "python",
   "name": "conda-env-dataMining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
